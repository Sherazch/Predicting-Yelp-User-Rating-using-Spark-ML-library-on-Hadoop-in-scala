{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.master=\"yarn\"\n",
    "launcher.num_executors=6\n",
    "launcher.executor_cores=2\n",
    "launcher.executor_memory='5000m'\n",
    "launcher.packages=[\"com.github.master:spark-stemming_2.10:0.2.0\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration: Extracting stars and reviews from review.json, and then find distribution of stars.                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://C570BD-HM-Master:8088/proxy/application_1543561993902_0002\n",
       "SparkContext available as 'sc' (version = 2.3.2, master = yarn, app id = application_1543561993902_0002)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-30 02:54:26 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2018-11-30 02:54:28 WARN  Client:66 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "2018-11-30 02:54:36 WARN  Client:66 - Same path resource file:///home/administrator/.ivy2/jars/com.github.master_spark-stemming_2.10-0.2.0.jar added multiple times to distributed cache.\n",
      "+-----+-------------+\n",
      "|stars|no_of_reviews|\n",
      "+-----+-------------+\n",
      "|    1|       731363|\n",
      "|    2|       438161|\n",
      "|    3|       615481|\n",
      "|    4|      1223316|\n",
      "|    5|      2253348|\n",
      "+-----+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "explore: Unit = ()\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Data Exploration\n",
    "val explore=spark.read.json(\"/hadoop-user/data/review.json\").select(\"Text\",\"Stars\").filter($\"Text\"!==\"\").\n",
    "filter($\"Stars\">=1).toDF(\"reviews\",\"stars\").createOrReplaceTempView(\"temp\")\n",
    "//sql(\"select * from temp\").show(20)\n",
    "\n",
    "//finding distribution of stars attribute\n",
    "sql(\"select stars,count(reviews) as no_of_reviews from temp group by stars order by stars ASC\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering: Assigning 1 or 0 according to the stars given by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|ratings|  total|\n",
      "+-------+-------+\n",
      "|      1|3476664|\n",
      "|      0|1785005|\n",
      "+-------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FE: org.apache.spark.sql.DataFrame = [stars: bigint, reviews: string ... 1 more field]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Feature Engineering \n",
    "val FE=sql(\"select stars,reviews,IF(stars>3,1,0) as ratings from temp\").toDF()\n",
    "FE.createOrReplaceTempView(\"Data\")\n",
    "//FE.show(20)\n",
    "//finding distribution of rating\n",
    "//sql(\"select * from Data\")\n",
    "sql(\"select ratings,Count(ratings) as total from Data Group by ratings\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As (1785005/3476664)=0.5134 so, we are now gonna down sample the data set using stratified sampling by keeping the lowest value as it is.\n",
    "As data set is so big so to only get its 10%, we are dividing the map fractions by 10. hence we are gonna Map 1->0.05134 times and 0 -> 0.1 times.\n",
    "\n",
    "PS: Don't use (1785005/3476664) while maping for fractions, instead use proper value 0.05134. It took me 3 days to figure out this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|ratings| count|\n",
      "+-------+------+\n",
      "|      1|178574|\n",
      "|      0|178418|\n",
      "+-------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "factor: scala.collection.immutable.Map[Int,Double] = Map(1 -> 0.05134, 0 -> 0.1)\n",
       "DownSampleData: org.apache.spark.sql.DataFrame = [stars: bigint, reviews: string ... 1 more field]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// DownSampling Data using Stratified Sampling\n",
    "val factor=Map(1 -> 0.05134, 0-> 0.1)\n",
    "val DownSampleData=FE.stat.sampleBy(\"ratings\",factor,111)\n",
    "DownSampleData.groupBy(\"ratings\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting TFIDF Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that the it is balanced!  ## Tokenization is the next step.\n",
    "We are gonna tokenize the reviews and then remove the punctuations from it and then after performing stemming, we will"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature._\n",
       "tokenized: org.apache.spark.ml.feature.RegexTokenizer = regexTok_abc701eff4e7\n",
       "import org.apache.spark.sql.functions.udf\n",
       "removePunc: (words: Seq[String])Seq[String]\n",
       "puncRemover: org.apache.spark.ml.feature.SQLTransformer = sql_b7f93e541c48\n",
       "stopWordRemover: org.apache.spark.ml.feature.StopWordsRemover = stopWords_153ba24d1948\n",
       "import org.apache.spark.mllib.feature.Stemmer\n",
       "stemmer: org.apache.spark.mllib.feature.Stemmer = stemmer_b6dee9900620\n",
       "vectorizer: org.apache.spark.ml.feature.CountVectorizer = cntVec_44df2b3bdfe2\n",
       "tfidf: org.apache.spark.ml.feature.IDF = idf_2ff562cda607\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature._\n",
    "\n",
    "val tokenized = new RegexTokenizer().setMinTokenLength(2).setToLowercase(true).\n",
    "setInputCol(\"reviews\").setOutputCol(\"words\")\n",
    "\n",
    "//Defining a udf to remove punctuations from a sequence of words\n",
    "import org.apache.spark.sql.functions.udf\n",
    "\n",
    "def removePunc(words:Seq[String]):Seq[String]={\n",
    " return words.map(_.replaceAll(\"\\\\p{Punct}\",\"\"))\n",
    "}\n",
    "\n",
    "spark.udf.register(\"removePuncUDF\",removePunc(_:Seq[String]) )\n",
    "\n",
    "//use the removePuncUDF to remove all punctuations from boilerplate_wordss\n",
    "val puncRemover = new SQLTransformer().\n",
    "setStatement(\"SELECT removePuncUDF(words) as punc_free_words, ratings from __THIS__ \")\n",
    "\n",
    "val stopWordRemover=new StopWordsRemover().setInputCol(\"punc_free_words\").setOutputCol(\"cleaned_words\")\n",
    "\n",
    "import org.apache.spark.mllib.feature.Stemmer\n",
    "val stemmer = new Stemmer().setInputCol(\"cleaned_words\").setOutputCol(\"stemmed_words\")\n",
    "\n",
    "val vectorizer = new CountVectorizer().setInputCol(\"stemmed_words\").setOutputCol(\"BOW\").setMinDF(100)\n",
    "\n",
    "val tfidf = new IDF().setInputCol(\"BOW\").setOutputCol(\"TFIDF_vector\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Logistic regression Model for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for predicting the stars, we are going to make Logistic Regression model exactly as we learnt in lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "import org.apache.spark.ml._\n",
       "import org.apache.spark.ml.regression._\n",
       "LR: org.apache.spark.ml.classification.LogisticRegression = logreg_52f0174b7a32\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml._\n",
    "import org.apache.spark.ml.regression._\n",
    "\n",
    "//Creating the logistic Regression model and fit it to the transformed training data\n",
    "val LR= new LogisticRegression().setLabelCol(\"ratings\").setFeaturesCol(\"TFIDF_vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating PipeLine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are gonna make pipeline for machine learning algos, we will put all the steps in pipelines that have to be followed orderly. every step of pipeline would be either transformer or estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_740b9d512678\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Creating a Pipeline and add the transformation we did so far to this pipeline\n",
    "val pipeline = new Pipeline().setStages(Array(tokenized,puncRemover,stopWordRemover,stemmer,vectorizer,tfidf,LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now As we have made pipeline, so we will now train and test our model and for that, \n",
    "we will split the downsampled data into training and testing sets. Here we are taking 80% data for training, \n",
    "and 20% for testing purpose as described in labs, however we can change the ratio as per requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [stars: bigint, reviews: string ... 1 more field]\n",
       "testing: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [stars: bigint, reviews: string ... 1 more field]\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Split the data randomly to 80% tranining and 20% testing. The training data is used to build the model and the testing data is used for testing the model\n",
    "val Array(training,testing)=DownSampleData.randomSplit(Array(0.8,0.2),111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are training the model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline_model: org.apache.spark.ml.PipelineModel = pipeline_740b9d512678\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Fitting the pipeline to the traning data and transforming the training data\n",
    "val pipeline_model = pipeline.fit(training)\n",
    "//training.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we are gonna test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------------+--------------------+\n",
      "|ratings|prediction|         Probability|       stemmed_words|\n",
      "+-------+----------+--------------------+--------------------+\n",
      "|      0|       0.0|[0.99999999712446...|[, reader, pleas,...|\n",
      "|      0|       0.0|[0.99123550037204...|[appar, arriv, 10...|\n",
      "|      0|       0.0|[0.97723998163800...|[star, walk, ladi...|\n",
      "|      0|       0.0|[0.95353909262916...|[star, make, sele...|\n",
      "|      0|       0.0|[0.96426454732683...|[1st, time, order...|\n",
      "|      0|       0.0|[0.99847967495729...|[2nd, time, ive, ...|\n",
      "|      0|       0.0|[0.99999854435074...|[6252017, 1030pm,...|\n",
      "|      0|       0.0|[0.99619023934215...|[good, friend, mi...|\n",
      "|      0|       0.0|[0.99999989216620...|[back, decid, wri...|\n",
      "|      0|       0.0|[0.99997896231672...|[alamo, hand, car...|\n",
      "|      0|       0.0|[0.96378236075468...|[avoid, appar, me...|\n",
      "|      0|       0.0|[0.99997228741567...|[absolut, aw, exp...|\n",
      "|      0|       0.0|[0.75213313181340...|[absolut, vile, c...|\n",
      "|      0|       0.0|[0.99997406904116...|[absolut, terribl...|\n",
      "|      0|       0.0|[0.97158747101823...|[experienc, excel...|\n",
      "+-------+----------+--------------------+--------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictions: org.apache.spark.sql.DataFrame = [punc_free_words: array<string>, ratings: int ... 7 more fields]\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Make predictions.\n",
    "val predictions = pipeline_model.transform(testing)\n",
    "\n",
    "// Select example rows to display.\n",
    "predictions.select(\"ratings\", \"prediction\",\"Probability\",\"stemmed_words\").show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation and AUC evaluators and Tuning of Hyper Parameters for Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using cross validation using 3 folds and Area Under the Curve to tune and evaluate the hyper parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------------+\n",
      "|ratings|prediction|       stemmed_words|\n",
      "+-------+----------+--------------------+\n",
      "|      0|       0.0|[, reader, pleas,...|\n",
      "|      0|       0.0|[appar, arriv, 10...|\n",
      "|      0|       0.0|[star, walk, ladi...|\n",
      "|      0|       0.0|[star, make, sele...|\n",
      "|      0|       0.0|[1st, time, order...|\n",
      "|      0|       0.0|[2nd, time, ive, ...|\n",
      "|      0|       0.0|[6252017, 1030pm,...|\n",
      "|      0|       0.0|[good, friend, mi...|\n",
      "|      0|       0.0|[back, decid, wri...|\n",
      "|      0|       0.0|[alamo, hand, car...|\n",
      "|      0|       0.0|[avoid, appar, me...|\n",
      "|      0|       0.0|[absolut, aw, exp...|\n",
      "|      0|       0.0|[absolut, vile, c...|\n",
      "|      0|       0.0|[absolut, terribl...|\n",
      "|      0|       0.0|[experienc, excel...|\n",
      "+-------+----------+--------------------+\n",
      "only showing top 15 rows\n",
      "\n",
      "Area under ROC curve(AUC) for LR on test data = 0.9438427887341851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.evaluation._\n",
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.apache.spark.ml.tuning._\n",
       "import org.apache.spark.ml.evaluation._\n",
       "import org.apache.spark.ml.feature._\n",
       "LR_new: org.apache.spark.ml.classification.LogisticRegression = logreg_72f55f220286\n",
       "paramGrid_LR: Array[org.apache.spark.ml.param.ParamMap] =\n",
       "Array({\n",
       "\tlogreg_72f55f220286-elasticNetParam: 0.0,\n",
       "\tidf_0f05023ff858-minDocFreq: 5,\n",
       "\tlogreg_72f55f220286-regParam: 0.01\n",
       "}, {\n",
       "\tlogreg_72f55f220286-elasticNetParam: 0.0,\n",
       "\tidf_0f05023ff858-minDocFreq: 5,\n",
       "\tlogreg_72f55f220286-regParam: 0.5\n",
       "}, {\n",
       "\tlogreg_72f55f220286-elasticNetParam: 0.0,\n",
       "\tidf_0f05023ff858-minDocFreq: 5,\n",
       "\tlogreg_72f55f220286-regParam: 2.0\n",
       "}, {\n",
       "\tlogreg_72f55f220286-elasticNet..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation._\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.tuning._\n",
    "import org.apache.spark.ml.evaluation._\n",
    "import org.apache.spark.ml.feature._\n",
    "\n",
    "\n",
    "val LR_new= new LogisticRegression().setLabelCol(\"ratings\").setFeaturesCol(\"TFIDF_vector\")\n",
    "\n",
    "val paramGrid_LR =new ParamGridBuilder()\n",
    "             .addGrid(LR_new.regParam, Array(0.01, 0.5, 2.0))\n",
    "             .addGrid(LR_new.elasticNetParam, Array(0.0, 0.5, 1.0))\n",
    "             .addGrid(tfidf.minDocFreq, Array(5,10))\n",
    "             .build()\n",
    "\n",
    "val evaluator_LR = new BinaryClassificationEvaluator().\n",
    "setRawPredictionCol(\"rawPrediction\").setLabelCol(\"ratings\").setMetricName(\"areaUnderROC\")\n",
    "\n",
    "val cv_LR = new CrossValidator().setEstimator(LR_new).setEvaluator(evaluator_LR).setEstimatorParamMaps(paramGrid_LR).setNumFolds(3)\n",
    "\n",
    "//Creating a Pipeline and add the transformation we did so far to this pipeline\n",
    "val pipeline_LR = new Pipeline().setStages(Array(tokenized,puncRemover,stopWordRemover,stemmer,vectorizer,tfidf,cv_LR))\n",
    "\n",
    "//Split the data randomly to 80% tranining and 20% testing. The training data is used to build the model and the testing data is used for testing the model\n",
    "val Array(trainingLR,testingLR)=DownSampleData.randomSplit(Array(0.8,0.2),111)\n",
    "\n",
    "//Fitting the pipeline to the traning data and transforming the training data\n",
    "val pipeline_modelLR = pipeline_LR.fit(trainingLR)\n",
    "\n",
    "// Make predictions.\n",
    "val predictionsLR = pipeline_modelLR.transform(testingLR)\n",
    "\n",
    "// Select example rows to display.\n",
    "predictionsLR.select(\"ratings\", \"prediction\",\"stemmed_words\").show(15)\n",
    "\n",
    "val AUC = evaluator_LR.evaluate(predictionsLR)\n",
    "println(s\"Area under ROC curve(AUC) for LR on test data = $AUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Area under ROC curve(AUC) for LR on test data = 0.9438427887341851\" is the result of AUC for Logistic regression, that means AUC is 94.38%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Random Forest Model for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for predicting the stars, we are going to make Linear Regression model exactly as we learnt in lab using \n",
    "RandomForestClassifier. Everything is almost same as we did for Linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.classification.RandomForestClassifier\n",
       "import org.apache.spark.ml.tuning._\n",
       "import org.apache.spark.ml.evaluation._\n",
       "import org.apache.spark.ml.feature._\n",
       "Random_Forest: org.apache.spark.ml.classification.RandomForestClassifier = rfc_e37cc74bfb0e\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.RandomForestClassifier\n",
    "import org.apache.spark.ml.tuning._\n",
    "import org.apache.spark.ml.evaluation._\n",
    "import org.apache.spark.ml.feature._\n",
    "\n",
    "//Building Random Forest Model\n",
    "val Random_Forest = new RandomForestClassifier().setLabelCol(\"ratings\").setFeaturesCol(\"TFIDF_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline_RF: org.apache.spark.ml.Pipeline = pipeline_624ae8d41db6\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Creating a Pipeline and add the transformation we did so far to this pipeline\n",
    "val pipeline_RF = new Pipeline().setStages(Array(tokenized,puncRemover,stopWordRemover,stemmer,vectorizer,tfidf,Random_Forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainingRF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [stars: bigint, reviews: string ... 1 more field]\n",
       "testingRF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [stars: bigint, reviews: string ... 1 more field]\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Split the data randomly to 80% tranining and 20% testing. \n",
    "val Array(trainingRF,testingRF)=DownSampleData.randomSplit(Array(0.8,0.2),111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline_model_RF: org.apache.spark.ml.PipelineModel = pipeline_624ae8d41db6\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Fitting the pipeline to the traning data and transforming the training data\n",
    "val pipeline_model_RF = pipeline_RF.fit(trainingRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------------+--------------------+\n",
      "|ratings|prediction|         Probability|       stemmed_words|\n",
      "+-------+----------+--------------------+--------------------+\n",
      "|      0|       0.0|[0.69062083508328...|[, reader, pleas,...|\n",
      "|      0|       0.0|[0.53001695905751...|[appar, arriv, 10...|\n",
      "|      0|       0.0|[0.51313455334488...|[star, walk, ladi...|\n",
      "|      0|       0.0|[0.52943907439286...|[star, make, sele...|\n",
      "|      0|       0.0|[0.51825493182364...|[1st, time, order...|\n",
      "|      0|       0.0|[0.60036818904750...|[2nd, time, ive, ...|\n",
      "|      0|       0.0|[0.63456268714765...|[6252017, 1030pm,...|\n",
      "|      0|       0.0|[0.52757052689521...|[good, friend, mi...|\n",
      "|      0|       0.0|[0.64726390682647...|[back, decid, wri...|\n",
      "|      0|       0.0|[0.69224997290498...|[alamo, hand, car...|\n",
      "|      0|       0.0|[0.50649827481452...|[avoid, appar, me...|\n",
      "|      0|       0.0|[0.57741458539382...|[absolut, aw, exp...|\n",
      "|      0|       1.0|[0.49996505819774...|[absolut, vile, c...|\n",
      "|      0|       0.0|[0.68558332894248...|[absolut, terribl...|\n",
      "|      0|       0.0|[0.61192754561419...|[experienc, excel...|\n",
      "+-------+----------+--------------------+--------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictionsRF: org.apache.spark.sql.DataFrame = [punc_free_words: array<string>, ratings: int ... 7 more fields]\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Make predictions.\n",
    "val predictionsRF = pipeline_model_RF.transform(testingRF)\n",
    "\n",
    "// Select example rows to display.\n",
    "predictionsRF.select(\"ratings\", \"prediction\",\"Probability\",\"stemmed_words\").show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation and AUC evaluators and Tuning of Hyper Parameters for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve(AUC) for RF on test data = 0.8443359946215225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.classification.RandomForestClassifier\n",
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.apache.spark.ml.tuning._\n",
       "import org.apache.spark.ml.evaluation._\n",
       "import org.apache.spark.ml.feature._\n",
       "rf1: org.apache.spark.ml.classification.RandomForestClassifier = rfc_1e3567b216fc\n",
       "paramGrid1: Array[org.apache.spark.ml.param.ParamMap] =\n",
       "Array({\n",
       "\trfc_1e3567b216fc-maxDepth: 2,\n",
       "\tidf_0f05023ff858-minDocFreq: 5,\n",
       "\trfc_1e3567b216fc-numTrees: 5\n",
       "}, {\n",
       "\trfc_1e3567b216fc-maxDepth: 2,\n",
       "\tidf_0f05023ff858-minDocFreq: 5,\n",
       "\trfc_1e3567b216fc-numTrees: 20\n",
       "}, {\n",
       "\trfc_1e3567b216fc-maxDepth: 5,\n",
       "\tidf_0f05023ff858-minDocFreq: 5,\n",
       "\trfc_1e3567b216fc-numTrees: 5\n",
       "}, {\n",
       "\trfc_1e3567b216fc-maxDepth: 5,\n",
       "\tidf_0f05023ff858-minDocFreq: 5,\n",
       "\trfc_1e3567b216fc-numTrees: 20\n",
       "}, {\n",
       "\trfc_1e3567b216fc-maxD..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.RandomForestClassifier\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.tuning._\n",
    "import org.apache.spark.ml.evaluation._\n",
    "import org.apache.spark.ml.feature._\n",
    "\n",
    "val rf1 = new RandomForestClassifier().setLabelCol(\"ratings\").setFeaturesCol(\"TFIDF_vector\")\n",
    "val paramGrid1 =new ParamGridBuilder()\n",
    "             .addGrid(rf1.maxDepth, Array(2, 5))\n",
    "             .addGrid(rf1.numTrees, Array(5, 20))\n",
    "             .addGrid(tfidf.minDocFreq, Array(5,10))\n",
    "             .build()\n",
    "\n",
    "val evaluator1 = new BinaryClassificationEvaluator().\n",
    "setRawPredictionCol(\"rawPrediction\").setLabelCol(\"ratings\").setMetricName(\"areaUnderROC\")\n",
    "\n",
    "\n",
    "val cv_rf = new CrossValidator().setEstimator(rf1).setEvaluator(evaluator1).\n",
    "setEstimatorParamMaps(paramGrid1).setNumFolds(3)\n",
    "\n",
    "val pipeline_rf1 = new Pipeline().setStages(Array(tokenized,puncRemover,stopWordRemover,stemmer,vectorizer,tfidf,cv_rf))\n",
    "\n",
    "val Array(training11,testing11)=DownSampleData.randomSplit(Array(0.8,0.2),111)\n",
    "\n",
    "//Fit the training data to the pipeline\n",
    "val pipelineModel_rf1 = pipeline_rf1.fit(training11)\n",
    "\n",
    "// Make predictions.\n",
    "val predictions11 = pipelineModel_rf1.transform(testing11)\n",
    "val AUC = evaluator1.evaluate(predictions11)\n",
    "println(s\"Area under ROC curve(AUC) for RF on test data = $AUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Area under ROC curve(AUC) for RF on test data = 0.8443359946215225\" This the AUC that means 84.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "java.lang.OutOfMemoryError",
     "evalue": " Java heap space",
     "output_type": "error",
     "traceback": [
      "java.lang.OutOfMemoryError: Java heap space",
      "  at java.util.Arrays.copyOf(Arrays.java:3236)",
      "  at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)",
      "  at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)",
      "  at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)",
      "  at org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)",
      "  at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)",
      "  at java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)",
      "  at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)",
      "  at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)",
      "  at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)",
      "  at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)",
      "  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:342)",
      "  at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:335)",
      "  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:159)",
      "  at org.apache.spark.SparkContext.clean(SparkContext.scala:2299)",
      "  at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1.apply(RDD.scala:850)",
      "  at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1.apply(RDD.scala:849)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
      "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)",
      "  at org.apache.spark.rdd.RDD.mapPartitionsWithIndex(RDD.scala:849)",
      "  at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:608)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)",
      "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.DeserializeToObjectExec.doExecute(objects.scala:89)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)",
      ""
     ]
    }
   ],
   "source": [
    "//Testing Only Purpose\n",
    "\n",
    "//GBT Regression\n",
    "\n",
    "import org.apache.spark.ml.regression.{GBTRegressionModel, GBTRegressor}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.tuning._\n",
    "import org.apache.spark.ml.evaluation._\n",
    "import org.apache.spark.ml.feature._\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val indexer=new StringIndexer().setInputCol(\"reviews\").setOutputCol(\"words_indexer\")\n",
    "\n",
    "//Now let's assemble everyting together in a feature vector\n",
    "val vectorizer1=new VectorAssembler().\n",
    "setInputCols(Array(\"words_indexer\")).setOutputCol(\"features\")\n",
    "\n",
    "// Create a GBT model.\n",
    "val gbt = new GBTRegressor()\n",
    "  .setLabelCol(\"ratings\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "\n",
    "\n",
    "\n",
    "//Create ParamGrid for Cross Validation\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "             .addGrid(gbt.maxDepth, Array(2,5))\n",
    "             .addGrid(gbt.maxIter, Array(10, 20,100))\n",
    "             .build()\n",
    "\n",
    "val evaluator = new BinaryClassificationEvaluator().\n",
    "setRawPredictionCol(\"rawPrediction\").setLabelCol(\"ratings\").setMetricName(\"areaUnderROC\")\n",
    "\n",
    "val cv = new CrossValidator().setEstimator(gbt).setEvaluator(evaluator).setEstimatorParamMaps(paramGrid).setNumFolds(3)\n",
    "\n",
    "\n",
    "val pipeline = new Pipeline().setStages(Array(indexer, vectorizer1,cv))\n",
    "\n",
    "\n",
    "val Array(training,testing)=DownSampleData.randomSplit(Array(0.8,0.2),111)\n",
    "\n",
    "//Fit the training data to the pipeline\n",
    "val pipelineModel = pipeline.fit(training)\n",
    "\n",
    "// Make predictions.\n",
    "val predictions = pipelineModel.transform(testing)\n",
    "\n",
    "// Select example rows to display.\n",
    "predictions.select(\"prediction\", \"ratings\", \"features\").show(5)\n",
    "\n",
    "val AUC = evaluator.evaluate(predictions)\n",
    "println(s\"Area Under the ROC Curve on test data = $AUC\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://C570BD-HM-Master:4040\n",
       "SparkContext available as 'sc' (version = 2.3.2, master = local[*], app id = local-1543567979390)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-30 02:52:58 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "ename": "<console>",
     "evalue": "41: error: not found: value DownSampleData",
     "output_type": "error",
     "traceback": [
      "<console>:41: error: not found: value DownSampleData",
      "         .fit(DownSampleData)",
      "              ^",
      "<console>:47: error: not found: value DownSampleData",
      "         .fit(DownSampleData)",
      "              ^",
      "<console>:51: error: not found: value DownSampleData",
      "       val Array(trainingData, testData) = DownSampleData.randomSplit(Array(0.8, 0.2))",
      "                                           ^",
      ""
     ]
    }
   ],
   "source": [
    "//GBT Classifier \n",
    "\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.classification.{GBTClassificationModel, GBTClassifier}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n",
    "import org.apache.spark.ml.regression.{GBTRegressionModel, GBTRegressor}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.tuning._\n",
    "import org.apache.spark.ml.evaluation._\n",
    "import org.apache.spark.ml.feature._\n",
    "\n",
    "\n",
    "\n",
    "val labelIndexer = new StringIndexer()\n",
    "  .setInputCol(\"ratings\")\n",
    "  .setOutputCol(\"indexedLabel\")\n",
    "  .fit(DownSampleData)\n",
    "\n",
    "val featureIndexer = new VectorIndexer()\n",
    "  .setInputCol(\"reviews\")\n",
    "  .setOutputCol(\"indexedFeatures\")\n",
    "  .setMaxCategories(4)\n",
    "  .fit(DownSampleData)\n",
    "\n",
    "\n",
    "// Split the data into training and test sets (30% held out for testing).\n",
    "val Array(trainingData, testData) = DownSampleData.randomSplit(Array(0.8, 0.2))\n",
    "\n",
    "// Train a GBT model.\n",
    "val gbt = new GBTClassifier()\n",
    "  .setLabelCol(\"indexedLabel\")\n",
    "  .setFeaturesCol(\"indexedFeatures\")\n",
    "  .setMaxIter(10)\n",
    "\n",
    "// Convert indexed labels back to original labels.\n",
    "val labelConverter = new IndexToString()\n",
    "  .setInputCol(\"prediction\")\n",
    "  .setOutputCol(\"predictedLabel\")\n",
    "  .setLabels(labelIndexer.labels)\n",
    "\n",
    "//Create ParamGrid for Cross Validation\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "             .addGrid(gbt.maxDepth, Array(2,5))\n",
    "             .addGrid(gbt.maxIter, Array(10, 20,100))\n",
    "             .build()\n",
    "\n",
    "val evaluator = new BinaryClassificationEvaluator().\n",
    "setRawPredictionCol(\"rawPrediction\").setLabelCol(\"ratings\").setMetricName(\"areaUnderROC\")\n",
    "\n",
    "val cv = new CrossValidator().setEstimator(gbt).setEvaluator(evaluator).setEstimatorParamMaps(paramGrid).setNumFolds(3)\n",
    "\n",
    "// Chain indexers and GBT in a Pipeline.\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(labelIndexer, featureIndexer, cv, labelConverter))\n",
    "\n",
    "// Train model. This also runs the indexers.\n",
    "val model = pipeline.fit(trainingData)\n",
    "\n",
    "// Make predictions.\n",
    "val predictions = model.transform(testData)\n",
    "\n",
    "// Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"ratings\", \"TFIDF_vector\").show(5)\n",
    "\n",
    "\n",
    "\n",
    "val AUC = evaluator.evaluate(predictions)\n",
    "println(s\"Area Under the ROC Curve on test data = $AUC\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Gradient Boosted Tree Regression Model for Rating Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are gonna predict the ratings using Gradient Boosted Tree (GBT) models using GBTRegressor. For that, we have to convert the String features to indicecs using StringIndexer and assemble all the features ( except the target variable) as a vector.  We are going to follow almost the same steps but a slight change only as explained in the labs. first we'll make the GBT model, then pipeline, then data splitting and then training and testing, and after that we will perform evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.regression.{GBTRegressionModel, GBTRegressor}\n",
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.apache.spark.ml.tuning._\n",
       "import org.apache.spark.ml.evaluation._\n",
       "import org.apache.spark.ml.feature._\n",
       "gbt: org.apache.spark.ml.regression.GBTRegressor = gbtr_0299445ceac1\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.{GBTRegressionModel, GBTRegressor}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.tuning._\n",
    "import org.apache.spark.ml.evaluation._\n",
    "import org.apache.spark.ml.feature._\n",
    "\n",
    "// Create a GBT model.\n",
    "val gbt = new GBTRegressor().setLabelCol(\"ratings\").setFeaturesCol(\"TFIDF_vector\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline_gbt: org.apache.spark.ml.Pipeline = pipeline_701c6ce0731a\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//making pipeline for GBT Regression\n",
    "val pipeline_gbt = new Pipeline().setStages(Array(tokenized,puncRemover,stopWordRemover,stemmer,vectorizer,tfidf,gbt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training_gbt: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [stars: bigint, reviews: string ... 1 more field]\n",
       "testing_gbt: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [stars: bigint, reviews: string ... 1 more field]\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Splitting data into training and testing sets\n",
    "val Array(training_gbt,testing_gbt)=DownSampleData.randomSplit(Array(0.8,0.2),111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipelineModel_gbt: org.apache.spark.ml.PipelineModel = pipeline_701c6ce0731a\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Fit the training data to the pipeline\n",
    "val pipelineModel_gbt = pipeline_gbt.fit(training_gbt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|ratings|          prediction|       stemmed_words|\n",
      "+-------+--------------------+--------------------+\n",
      "|      0|-0.11536258114046004|[, reader, pleas,...|\n",
      "|      0| 0.21778032076752749|[appar, arriv, 10...|\n",
      "|      0| 0.25089040713640864|[star, walk, ladi...|\n",
      "|      0| 0.11048811651336213|[star, make, sele...|\n",
      "|      0| 0.18723617479923235|[1st, time, order...|\n",
      "|      0| 0.07677282414354611|[2nd, time, ive, ...|\n",
      "|      0|-0.06641511722031082|[6252017, 1030pm,...|\n",
      "|      0|  0.4352886560959326|[good, friend, mi...|\n",
      "|      0|-0.09895209726060106|[back, decid, wri...|\n",
      "|      0| 0.04591080097629264|[alamo, hand, car...|\n",
      "|      0|  0.3683313337001561|[avoid, appar, me...|\n",
      "|      0| 0.10615398411210614|[absolut, aw, exp...|\n",
      "|      0| 0.33517389492886956|[absolut, vile, c...|\n",
      "|      0|-0.13450946429206584|[absolut, terribl...|\n",
      "|      0|  0.6332569431092511|[experienc, excel...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictions_gbt: org.apache.spark.sql.DataFrame = [punc_free_words: array<string>, ratings: int ... 5 more fields]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Make predictions.\n",
    "val predictions_gbt = pipelineModel_gbt.transform(testing_gbt)\n",
    "\n",
    "// Select example rows to display.\n",
    "predictions_gbt.select(\"ratings\", \"prediction\",\"stemmed_words\").show(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation and AUC evaluators and Tuning of Hyper Parameters for Gradient-Boosted Trees (GBT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.regression.{GBTRegressionModel, GBTRegressor}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.tuning._\n",
    "import org.apache.spark.ml.evaluation._\n",
    "import org.apache.spark.ml.feature._\n",
    "\n",
    "// Create a GBT model.\n",
    "val gbt1 = new GBTRegressor().setLabelCol(\"ratings\").setFeaturesCol(\"TFIDF_vector\")\n",
    "\n",
    "\n",
    "//Create ParamGrid for Cross Validation\n",
    "val paramGrid_gbt = new ParamGridBuilder()\n",
    "             .addGrid(gbt.maxDepth, Array(2,5))\n",
    "             .addGrid(gbt.maxIter, Array(10, 20,100))\n",
    "             .build()\n",
    "\n",
    "//Evaluators for GBT\n",
    "val evaluator_gbt = new BinaryClassificationEvaluator().\n",
    "setLabelCol(\"ratings\").setMetricName(\"areaUnderROC\")\n",
    "\n",
    "//cross validation with 3 folds\n",
    "val cv_gbt = new CrossValidator().setEstimator(gbt1).\n",
    "setEvaluator(evaluator_gbt).setEstimatorParamMaps(paramGrid_gbt).setNumFolds(3)\n",
    "\n",
    "//making pipeline for GBT Regression\n",
    "val pipeline_gbt1 = new Pipeline().setStages(Array(tokenized,puncRemover,stopWordRemover,stemmer,vectorizer,tfidf,cv_gbt))\n",
    "\n",
    "//Splitting data into training and testing sets\n",
    "val Array(training_gbt1,testing_gbt1)=DownSampleData.randomSplit(Array(0.8,0.2),111)\n",
    "\n",
    "//Fit the training data to the pipeline\n",
    "val pipelineModel_gbt1 = pipeline_gbt1.fit(training_gbt1)\n",
    "\n",
    "// Make predictions.\n",
    "val predictions_gbt1 = pipelineModel_gbt1.transform(testing_gbt1)\n",
    "\n",
    "// Select example rows to display.\n",
    "predictions_gbt1.select(\"ratings\", \"prediction\",\"stemmed_words\").show(15)\n",
    "\n",
    "val AUC_gbt = evaluator_gbt.evaluate(predictions_gbt1)\n",
    "println(s\"Area under ROC curve(AUC) for RF on test data = $AUC_gbt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the AUC value for GBT is .3419 that means 34.19%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, seeing the AUC of all the three model, we can clearly see that the logictic regression have highest value of AUC that is \"94.38%\". So we can conclude that Logistic Regression idid the better job for predicting the ratings based on the reviews given by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling the prediction of all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, We are going to take the predictions generated by the three models above (that is,logistic regression and random forest, and gradient boosted classification tree), zip them together and compute a “prediction_ensembled” column which is basically a majority vote of the three prediction columns generated by each model. That is, if two or more of the models generated the same prediction,then use that prediction in the prediction_ensembled column; otherwise, if none of the predictions are the same, then use the rating value1 for the prediction_ensemble column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsLR.toDF().createOrReplaceTempView(\"LR_Output\")\n",
    "predictionsRF.toDF().createOrReplaceTempView(\"RF_Output\")\n",
    "predictions_gbt.toDF().createOrReplaceTempView(\"GBT_Output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering the prediction from all 3 models and then finding the ensembeled prediction as described in the assignment. Here, The logic I am following is as the prediction will always be either 1 or 0. So, if 2 or more models will predict 1 then the sum of all the 3 predictions will always be greater then 1 and else it will remain 0.\n",
    "\n",
    "PS: Respected ma'am, I don't know wheather my approach to ensemble the predictions is right or not but after trying so many other things, I preffered to follow the simplest thing I understood from the instructions given in Assignmnet 5. However, I was doing something like this https://spark.apache.org/docs/1.6.2/mllib-ensembles.html ,don't know I was right or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val ensemble=spark.sql(\"select a.ratings As Original_Ratings,CASE WHEN (a.prediction + b.prediction + c.prediction)>1 THEN 1 ELSE 0 END AS prediction_ensemble\"+\n",
    "\"from LR_Output a,  RF_Output b, GBT_Output c \"+\n",
    "\"where a.TFIDF_vector=b.TFIDF_vector AND b.TFIDF_vector=c.TFIDF_vector\").toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting ensemble DF into RDD and then finding the accuracy of ensembled prediction, using Area under the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Importing the required libraries\n",
    "import spark.implicits._\n",
    "import org.apache.spark.mllib.evaluation._\n",
    "\n",
    "//Converting the ensemble dataframe to an rdd of the form (prediction_ensemble, ratings)\n",
    "val predictionsAndLabels=ensemble.selectExpr(\"cast(prediction_ensemble as\n",
    "Double) prediction_ensemble\", \"cast(ratings as Double) ratings\").rdd.\n",
    "map(row =>(row.getAs[Double](\"prediction_ensemble\"),row.getAs[Double](\"ratings\")))\n",
    "\n",
    "//Compute the accuracy of the ensemble predictions\n",
    "val metrics= new BinaryClassificationMetrics( predictionsAndLabels)\n",
    "println(metrics.areaUnderROC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********** THE END ****************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
